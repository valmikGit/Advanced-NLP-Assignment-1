{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc05f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "train_cls_head_only.py\n",
    "\n",
    "Train only the classification head on top of a frozen BERT encoder\n",
    "using CLS token pooling, then evaluate on a test set.\n",
    "\n",
    "CSV schema: question_id, turn, turn_1_query, turn_1_answer, turn_2_query, winner\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Argument parsing\n",
    "# -------------------------\n",
    "def parse_args():\n",
    "    p = argparse.ArgumentParser(description=\"Train only classification head on frozen BERT\")\n",
    "    p.add_argument(\"--csv\", type=str, default=\"mt_bench_training.csv\", help=\"Input CSV file path\")\n",
    "    p.add_argument(\"--output_dir\", type=str, default=\"./bert_cls_head\", help=\"Where to save trained model\")\n",
    "    p.add_argument(\"--model_name\", type=str, default=\"bert-base-uncased\", help=\"Pretrained BERT model\")\n",
    "    p.add_argument(\"--batch_size\", type=int, default=8)\n",
    "    p.add_argument(\"--epochs\", type=int, default=3)\n",
    "    p.add_argument(\"--lr\", type=float, default=5e-5)\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "    p.add_argument(\"--max_length\", type=int, default=256)\n",
    "    return p.parse_args()\n",
    "\n",
    "# -------------------------\n",
    "# Utilities\n",
    "# -------------------------\n",
    "def build_text_from_row(row):\n",
    "    \"\"\"Format row into natural language text.\"\"\"\n",
    "    turn = int(row[\"turn\"])\n",
    "    q1 = str(row.get(\"turn_1_query\", \"\")).strip()\n",
    "    if turn == 1:\n",
    "        return f\"Turn 1 query: {q1}\"\n",
    "    elif turn == 2:\n",
    "        ans = str(row.get(\"turn_1_answer\", \"\")).strip()\n",
    "        q2 = str(row.get(\"turn_2_query\", \"\")).strip()\n",
    "        return f\"Turn 1 query: {q1}, Turn 1 answer: {ans}, Turn 2 query: {q2}\"\n",
    "    else:\n",
    "        return f\"Turn 1 query: {q1}\"\n",
    "\n",
    "def preprocess_dataset(df, tokenizer, label2id, args):\n",
    "    \"\"\"Convert DataFrame into HF Dataset with tokenized inputs and labels.\"\"\"\n",
    "    texts = [build_text_from_row(r) for _, r in df.iterrows()]\n",
    "    labels = [label2id[w] for w in df[\"winner\"]]\n",
    "    encodings = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "        max_length=args.max_length,\n",
    "    )\n",
    "    dataset = Dataset.from_dict({**encodings, \"labels\": labels})\n",
    "    return dataset\n",
    "\n",
    "# -------------------------\n",
    "# Main\n",
    "# -------------------------\n",
    "def main():\n",
    "    args = parse_args()\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    # Load dataset\n",
    "    if not os.path.exists(args.csv):\n",
    "        raise FileNotFoundError(f\"CSV not found: {args.csv}\")\n",
    "    df = pd.read_csv(args.csv)\n",
    "    unique_labels = sorted(df[\"winner\"].unique().tolist())\n",
    "    print(f\"Unique labels: {unique_labels}\")\n",
    "\n",
    "    label2id = {label: i for i, label in enumerate(unique_labels)}\n",
    "    id2label = {i: label for i, label in enumerate(unique_labels)}\n",
    "\n",
    "    # Split dataset\n",
    "    train_df, test_df = train_test_split(df, test_size=0.1, random_state=args.seed, stratify=df[\"winner\"])\n",
    "    train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=args.seed, stratify=train_df[\"winner\"])\n",
    "\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.model_name)\n",
    "\n",
    "    # Tokenize datasets\n",
    "    train_ds = preprocess_dataset(train_df, tokenizer, label2id, args)\n",
    "    val_ds = preprocess_dataset(val_df, tokenizer, label2id, args)\n",
    "    test_ds = preprocess_dataset(test_df, tokenizer, label2id, args)\n",
    "\n",
    "    # Load model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        args.model_name,\n",
    "        num_labels=len(unique_labels),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "\n",
    "    # Freeze all BERT parameters\n",
    "    for param in model.base_model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Ensure classification head is trainable\n",
    "    for param in model.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    print(\"Trainable parameters:\")\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(name)\n",
    "\n",
    "    # Data collator\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=args.output_dir,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=args.batch_size,\n",
    "        per_device_eval_batch_size=args.batch_size,\n",
    "        num_train_epochs=args.epochs,\n",
    "        learning_rate=args.lr,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        greater_is_better=True,\n",
    "        logging_dir=os.path.join(args.output_dir, \"logs\"),\n",
    "        seed=args.seed,\n",
    "    )\n",
    "\n",
    "    # Metric\n",
    "    def compute_metrics(eval_preds):\n",
    "        logits, labels = eval_preds\n",
    "        preds = np.argmax(logits, axis=-1)\n",
    "        acc = (preds == labels).mean()\n",
    "        return {\"accuracy\": acc}\n",
    "\n",
    "    # Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=val_ds,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    print(\"--- Training classification head ---\")\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate on test set\n",
    "    print(\"--- Evaluating on test set ---\")\n",
    "    results = trainer.evaluate(test_ds)\n",
    "    print(results)\n",
    "\n",
    "    # Save model\n",
    "    model.save_pretrained(args.output_dir)\n",
    "    tokenizer.save_pretrained(args.output_dir)\n",
    "    print(f\"Model saved to {args.output_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignmentenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
