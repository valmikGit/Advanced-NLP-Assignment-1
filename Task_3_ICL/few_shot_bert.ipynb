{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc05f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "few_shot_bert_icL.py\n",
    "\n",
    "Use BERT in few-shot in-context learning mode (n-shots) to classify the best model.\n",
    "\n",
    "Pipeline:\n",
    "1. Randomly choose a row from the CSV -> this is the \"query\" we want to predict.\n",
    "2. Randomly select n other distinct rows as few-shot demonstrations.\n",
    "3. Build a prompt of the form:\n",
    "\n",
    "   Query: {query_1}, winner model: {winner_1}\n",
    "   ...\n",
    "   Query: {query_n}, winner model: {winner_n}\n",
    "   Turn 1 query: {target_query}, winner model: [MASK]\n",
    "\n",
    "4. Pass this prompt into a BERT MLM head, predict the masked token.\n",
    "5. Repeat for 100 queries, save results to CSV.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------\n",
    "# Argument parsing\n",
    "# -------------------------\n",
    "def parse_args():\n",
    "    p = argparse.ArgumentParser(description=\"Few-shot ICL with BERT for model classification\")\n",
    "    p.add_argument(\"--csv\", type=str, default=\"mt_bench_training.csv\", help=\"Input CSV file path\")\n",
    "    p.add_argument(\"--output_csv\", type=str, default=\"bert_few_shot_predictions.csv\", help=\"Output CSV file path\")\n",
    "    p.add_argument(\"--model_name\", type=str, default=\"bert-base-uncased\", help=\"Pretrained BERT model\")\n",
    "    p.add_argument(\"--shots\", type=int, default=1, help=\"Number of shots (examples) for few-shot ICL\")\n",
    "    p.add_argument(\"--num_queries\", type=int, default=100, help=\"Number of queries to evaluate\")\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "    return p.parse_args()\n",
    "\n",
    "# -------------------------\n",
    "# Utilities\n",
    "# -------------------------\n",
    "def build_text_from_row(row):\n",
    "    \"\"\"Format a row into natural language text based on turn.\"\"\"\n",
    "    turn = int(row[\"turn\"])\n",
    "    q1 = str(row.get(\"turn_1_query\", \"\")).strip()\n",
    "    if turn == 1:\n",
    "        return f\"Turn 1 query: {q1}\"\n",
    "    elif turn == 2:\n",
    "        ans = str(row.get(\"turn_1_answer\", \"\")).strip()\n",
    "        q2 = str(row.get(\"turn_2_query\", \"\")).strip()\n",
    "        return f\"Turn 1 query: {q1}, Turn 1 answer: {ans}, Turn 2 query: {q2}\"\n",
    "    else:\n",
    "        return f\"Turn 1 query: {q1}\"\n",
    "\n",
    "def build_prompt(few_shots, target_row):\n",
    "    \"\"\"Build the full few-shot prompt ending with 'winner model: [MASK]'.\"\"\"\n",
    "    parts = []\n",
    "    for row in few_shots:\n",
    "        query_text = build_text_from_row(row)\n",
    "        parts.append(f\"{query_text}, winner model: {row['winner']}\")\n",
    "    target_query_text = build_text_from_row(target_row)\n",
    "    parts.append(f\"{target_query_text}, winner model: [MASK]\")\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "def predict_masked(prompt, tokenizer, model, candidate_labels):\n",
    "    \"\"\"Predict which candidate label fills [MASK] best.\"\"\"\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    mask_token_logits = logits[0, mask_token_index, :].squeeze(0)\n",
    "\n",
    "    # Score each candidate by summing token logit probs\n",
    "    candidate_scores = {}\n",
    "    for label in candidate_labels:\n",
    "        label_ids = tokenizer(label, add_special_tokens=False)[\"input_ids\"]\n",
    "        if len(label_ids) == 1:\n",
    "            score = mask_token_logits[label_ids[0]].item()\n",
    "        else:\n",
    "            # Approximate: average scores for multi-token labels\n",
    "            score = np.mean([mask_token_logits[i].item() for i in label_ids])\n",
    "        candidate_scores[label] = score\n",
    "\n",
    "    # Pick the highest-scoring candidate\n",
    "    pred = max(candidate_scores, key=candidate_scores.get)\n",
    "    return pred, candidate_scores\n",
    "\n",
    "# -------------------------\n",
    "# Main\n",
    "# -------------------------\n",
    "def main():\n",
    "    args = parse_args()\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    # Load dataset\n",
    "    if not os.path.exists(args.csv):\n",
    "        raise FileNotFoundError(f\"CSV not found: {args.csv}\")\n",
    "    df = pd.read_csv(args.csv)\n",
    "    unique_labels = sorted(df[\"winner\"].unique().tolist())\n",
    "    print(f\"Unique labels: {unique_labels}\")\n",
    "\n",
    "    # Load BERT MLM model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.model_name)\n",
    "    model = AutoModelForMaskedLM.from_pretrained(args.model_name)\n",
    "    model.eval()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i in range(args.num_queries):\n",
    "        # 1. Pick a target row\n",
    "        target_idx = random.randint(0, len(df) - 1)\n",
    "        target_row = df.iloc[target_idx]\n",
    "\n",
    "        # 2. Select few-shot examples (ensure distinct from target)\n",
    "        few_shot_indices = random.sample(\n",
    "            [j for j in range(len(df)) if j != target_idx],\n",
    "            k=min(args.shots, len(df)-1)\n",
    "        )\n",
    "        few_shots = [df.iloc[j] for j in few_shot_indices]\n",
    "\n",
    "        # 3. Build prompt\n",
    "        prompt = build_prompt(few_shots, target_row)\n",
    "\n",
    "        # 4. Predict [MASK]\n",
    "        pred, scores = predict_masked(prompt, tokenizer, model, unique_labels)\n",
    "\n",
    "        # Record result\n",
    "        results.append({\n",
    "            \"query_id\": target_row[\"question_id\"],\n",
    "            \"turn\": target_row[\"turn\"],\n",
    "            \"true_winner\": target_row[\"winner\"],\n",
    "            \"predicted_winner\": pred,\n",
    "            \"prompt\": prompt,\n",
    "            \"scores\": scores\n",
    "        })\n",
    "\n",
    "        print(f\"[{i+1}/{args.num_queries}] True: {target_row['winner']} | Pred: {pred}\")\n",
    "\n",
    "    # Save results to CSV\n",
    "    out_df = pd.DataFrame(results)\n",
    "    out_df.to_csv(args.output_csv, index=False)\n",
    "    print(f\"Saved predictions to {args.output_csv}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignmentenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
